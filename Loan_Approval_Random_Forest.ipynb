{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import RFECV\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/loan_data.csv')\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = data.drop('loan_status', axis=1)\n",
        "y = data['loan_status']\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = [col for col in X.columns if X[col].dtype == 'object']\n",
        "\n",
        "# Create a preprocessor to handle categorical variables\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)],\n",
        "    remainder='passthrough')\n",
        "\n",
        "# Split into training and testing sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345, stratify=y)\n",
        "\n",
        "# Fit the preprocessor and transform the data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "# Apply RandomUnderSampler for undersampling\n",
        "rus = RandomUnderSampler(random_state=12345, sampling_strategy='auto')\n",
        "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Print class distribution after undersampling\n",
        "print(\"Class distribution after undersampling:\")\n",
        "print(pd.Series(y_train_resampled).value_counts())\n",
        "\n",
        "# Define a function to train and evaluate the model\n",
        "def train_and_evaluate(X_train_data, y_train_data, X_test_data, y_test_data):\n",
        "    # Initialize the base RandomForestClassifier\n",
        "    rf_base = RandomForestClassifier(random_state=12345, class_weight='balanced', n_estimators=100)\n",
        "\n",
        "    # Use RFECV for feature selection\n",
        "    rfecv = RFECV(estimator=rf_base, step=1, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "    X_train_selected = rfecv.fit_transform(X_train_data, y_train_data)\n",
        "    X_test_selected = rfecv.transform(X_test_data)\n",
        "\n",
        "    # Get feature names after one-hot encoding\n",
        "    feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "    # Filter selected features using RFECV support mask\n",
        "    selected_features = np.array(feature_names)[rfecv.support_]\n",
        "\n",
        "    print(\"\\nSelected Features:\")\n",
        "    print(selected_features)\n",
        "\n",
        "    # Print the number of selected features\n",
        "    print(f\"\\nOptimal number of features: {rfecv.n_features_}\")\n",
        "\n",
        "    # Define the parameter grid for Random Forest\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 500],\n",
        "        'max_depth': [10, 15, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2],\n",
        "        'criterion': ['gini'],\n",
        "        'class_weight': [None, 'balanced']\n",
        "    }\n",
        "\n",
        "    # Initialize GridSearchCV with feature-selected data\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=12345),\n",
        "        param_grid=param_grid,\n",
        "        cv=3,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train_selected, y_train_data)\n",
        "\n",
        "    # Print the best parameters\n",
        "    print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n",
        "\n",
        "    # Train the final model with the best parameters\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=grid_search.best_params_['n_estimators'],\n",
        "        max_depth=grid_search.best_params_['max_depth'],\n",
        "        min_samples_split=grid_search.best_params_['min_samples_split'],\n",
        "        min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
        "        criterion=grid_search.best_params_['criterion'],\n",
        "        class_weight=grid_search.best_params_['class_weight'],\n",
        "        random_state=12345\n",
        "    )\n",
        "\n",
        "    rf_model.fit(X_train_selected, y_train_data)\n",
        "\n",
        "    # Predict on training and test sets\n",
        "    y_train_pred = rf_model.predict(X_train_selected)\n",
        "    y_test_pred = rf_model.predict(X_test_selected)\n",
        "\n",
        "    # Compute and print training and test metrics\n",
        "    def compute_metrics(y_true, y_pred):\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "        recall = tp / (tp + fn)  # Sensitivity (True Positive Rate)\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        specificity = tn / (tn + fp)  # True Negative Rate\n",
        "\n",
        "        return accuracy, recall, precision, specificity\n",
        "\n",
        "    # Compute and print training metrics\n",
        "    train_accuracy, train_recall, train_precision, train_specificity = compute_metrics(y_train_data, y_train_pred)\n",
        "    print(\"\\nTraining Set Metrics:\")\n",
        "    print(f\"Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Recall (Sensitivity): {train_recall:.4f}\")\n",
        "    print(f\"Precision: {train_precision:.4f}\")\n",
        "    print(f\"Specificity: {train_specificity:.4f}\")\n",
        "\n",
        "    # Compute and print test metrics\n",
        "    test_accuracy, test_recall, test_precision, test_specificity = compute_metrics(y_test_data, y_test_pred)\n",
        "    print(\"\\nTest Set Metrics:\")\n",
        "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Recall (Sensitivity): {test_recall:.4f}\")\n",
        "    print(f\"Precision: {test_precision:.4f}\")\n",
        "    print(f\"Specificity: {test_specificity:.4f}\")\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report (Training Set):\")\n",
        "    print(classification_report(y_train_data, y_train_pred))\n",
        "\n",
        "    print(\"\\nClassification Report (Test Set):\")\n",
        "    print(classification_report(y_test_data, y_test_pred))\n",
        "\n",
        "    # Print confusion matrices for both training and test sets\n",
        "    print(\"\\nConfusion Matrix (Training Set):\")\n",
        "    print(confusion_matrix(y_train_data, y_train_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix (Test Set):\")\n",
        "    print(confusion_matrix(y_test_data, y_test_pred))\n",
        "\n",
        "    return rf_model\n",
        "\n",
        "# Train and evaluate on the original (imbalanced) data\n",
        "print(\"\\n--- Results for Original (Imbalanced) Class Distribution ---\")\n",
        "rf_model_imbalanced = train_and_evaluate(X_train_transformed, y_train, X_test_transformed, y_test)\n",
        "\n",
        "# Train and evaluate on the undersampled data\n",
        "print(\"\\n--- Results for Undersampled Class Distribution ---\")\n",
        "rf_model_undersampled = train_and_evaluate(X_train_resampled, y_train_resampled, X_test_transformed, y_test)\n",
        "\n",
        "# Save both models\n",
        "joblib.dump(rf_model_imbalanced, '/content/random_forest_model_imbalanced.pkl')\n",
        "joblib.dump(rf_model_undersampled, '/content/random_forest_model_undersampled.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPFpKonCznE7",
        "outputId": "f50f90d3-94d6-496e-89f8-4e02dd59e44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after undersampling:\n",
            "loan_status\n",
            "0    8000\n",
            "1    8000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Results for Original (Imbalanced) Class Distribution ---\n",
            "\n",
            "Selected Features:\n",
            "['cat__person_gender_female' 'cat__person_education_Bachelor'\n",
            " 'cat__person_home_ownership_MORTGAGE' 'cat__person_home_ownership_OWN'\n",
            " 'cat__person_home_ownership_RENT' 'cat__loan_intent_DEBTCONSOLIDATION'\n",
            " 'cat__loan_intent_EDUCATION' 'cat__loan_intent_HOMEIMPROVEMENT'\n",
            " 'cat__loan_intent_MEDICAL' 'cat__loan_intent_VENTURE'\n",
            " 'cat__previous_loan_defaults_on_file_No'\n",
            " 'cat__previous_loan_defaults_on_file_Yes' 'remainder__person_age'\n",
            " 'remainder__person_income' 'remainder__person_emp_exp'\n",
            " 'remainder__loan_amnt' 'remainder__loan_int_rate'\n",
            " 'remainder__loan_percent_income' 'remainder__cb_person_cred_hist_length'\n",
            " 'remainder__credit_score']\n",
            "\n",
            "Optimal number of features: 20\n",
            "Best parameters from GridSearchCV: {'class_weight': None, 'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
            "\n",
            "Training Set Metrics:\n",
            "Accuracy: 0.9954\n",
            "Recall (Sensitivity): 0.9792\n",
            "Precision: 1.0000\n",
            "Specificity: 1.0000\n",
            "\n",
            "Test Set Metrics:\n",
            "Accuracy: 0.9256\n",
            "Recall (Sensitivity): 0.7505\n",
            "Precision: 0.8977\n",
            "Specificity: 0.9756\n",
            "\n",
            "Classification Report (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00     28000\n",
            "           1       1.00      0.98      0.99      8000\n",
            "\n",
            "    accuracy                           1.00     36000\n",
            "   macro avg       1.00      0.99      0.99     36000\n",
            "weighted avg       1.00      1.00      1.00     36000\n",
            "\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      7000\n",
            "           1       0.90      0.75      0.82      2000\n",
            "\n",
            "    accuracy                           0.93      9000\n",
            "   macro avg       0.91      0.86      0.89      9000\n",
            "weighted avg       0.92      0.93      0.92      9000\n",
            "\n",
            "\n",
            "Confusion Matrix (Training Set):\n",
            "[[28000     0]\n",
            " [  166  7834]]\n",
            "\n",
            "Confusion Matrix (Test Set):\n",
            "[[6829  171]\n",
            " [ 499 1501]]\n",
            "\n",
            "--- Results for Undersampled Class Distribution ---\n",
            "\n",
            "Selected Features:\n",
            "['cat__person_gender_female' 'cat__person_gender_male'\n",
            " 'cat__person_education_Associate' 'cat__person_education_Bachelor'\n",
            " 'cat__person_education_High School' 'cat__person_home_ownership_MORTGAGE'\n",
            " 'cat__person_home_ownership_OWN' 'cat__person_home_ownership_RENT'\n",
            " 'cat__loan_intent_DEBTCONSOLIDATION' 'cat__loan_intent_EDUCATION'\n",
            " 'cat__loan_intent_HOMEIMPROVEMENT' 'cat__loan_intent_MEDICAL'\n",
            " 'cat__loan_intent_PERSONAL' 'cat__loan_intent_VENTURE'\n",
            " 'cat__previous_loan_defaults_on_file_No'\n",
            " 'cat__previous_loan_defaults_on_file_Yes' 'remainder__person_age'\n",
            " 'remainder__person_income' 'remainder__person_emp_exp'\n",
            " 'remainder__loan_amnt' 'remainder__loan_int_rate'\n",
            " 'remainder__loan_percent_income' 'remainder__cb_person_cred_hist_length'\n",
            " 'remainder__credit_score']\n",
            "\n",
            "Optimal number of features: 24\n",
            "Best parameters from GridSearchCV: {'class_weight': None, 'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
            "\n",
            "Training Set Metrics:\n",
            "Accuracy: 0.9948\n",
            "Recall (Sensitivity): 0.9992\n",
            "Precision: 0.9905\n",
            "Specificity: 0.9904\n",
            "\n",
            "Test Set Metrics:\n",
            "Accuracy: 0.8862\n",
            "Recall (Sensitivity): 0.9300\n",
            "Precision: 0.6778\n",
            "Specificity: 0.8737\n",
            "\n",
            "Classification Report (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      8000\n",
            "           1       0.99      1.00      0.99      8000\n",
            "\n",
            "    accuracy                           0.99     16000\n",
            "   macro avg       0.99      0.99      0.99     16000\n",
            "weighted avg       0.99      0.99      0.99     16000\n",
            "\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92      7000\n",
            "           1       0.68      0.93      0.78      2000\n",
            "\n",
            "    accuracy                           0.89      9000\n",
            "   macro avg       0.83      0.90      0.85      9000\n",
            "weighted avg       0.91      0.89      0.89      9000\n",
            "\n",
            "\n",
            "Confusion Matrix (Training Set):\n",
            "[[7923   77]\n",
            " [   6 7994]]\n",
            "\n",
            "Confusion Matrix (Test Set):\n",
            "[[6116  884]\n",
            " [ 140 1860]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/random_forest_model_undersampled.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the preprocessor\n",
        "joblib.dump(preprocessor, '/content/preprocessor.pkl')\n",
        "\n",
        "# Save the feature names after preprocessing\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "joblib.dump(feature_names, '/content/feature_names.pkl')\n",
        "\n",
        "# Save categorical columns (for reference)\n",
        "joblib.dump(categorical_columns, '/content/categorical_columns.pkl')\n",
        "\n",
        "# Save class labels (for reference)\n",
        "class_labels = y.unique()\n",
        "joblib.dump(class_labels, '/content/class_labels.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpfRh1gPIciL",
        "outputId": "60a1b0d6-b157-456b-f996-b1cf8e6f96fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/class_labels.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask joblib pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlS-J3N0HSHl",
        "outputId": "104a9bdb-c417-42f6-ebf0-96eb9feb980a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load('/content/random_forest_model_undersampled.pkl')\n",
        "\n",
        "# Load the preprocessor (if needed)\n",
        "preprocessor = joblib.load('/content/preprocessor.pkl')  # Save this during training if required\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define a route for predictions\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        # Get JSON data from the request\n",
        "        input_data = request.json\n",
        "\n",
        "        # Convert input data into a DataFrame\n",
        "        input_df = pd.DataFrame(input_data)\n",
        "\n",
        "        # Preprocess the input data (if required)\n",
        "        input_transformed = preprocessor.transform(input_df)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(input_transformed)\n",
        "\n",
        "        # Return predictions as JSON\n",
        "        return jsonify({'predictions': predictions.tolist()})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)})\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxz-4FirHXW7",
        "outputId": "d30f31cc-88c1-4a11-b2a9-4e5dfd607136"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}